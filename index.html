<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>首姿勢＋顔距離(Z)判定</title>
  <style>
    body {
      font-size: 24px;
      text-align: center;
      margin: 0;
      padding: 0;
    }
    #content {
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100vh;
    }
    /* 横並び用のラッパ */
    .video-area {
      display: flex;
      flex-direction: row;
      gap: 12px;
      justify-content: center;
      align-items: center;
      margin-top: 12px;
    }
    video, canvas {
      transform: scaleX(-1);
      width: 360px;
      height: 480px;
      border: 1px solid #ccc;
    }
    #output {
      white-space: pre-line;
      font-weight: bold;
      margin-top: 12px;
    }
    #warning {
      font-size: 32px;
      font-weight: bold;
      margin-top: 16px;
    }
    #startBtn {
      font-size: 24px;
      margin: 12px;
      padding: 8px 24px;
    }
  </style>
</head>
<body>
  <div id="content">
    <h1>首姿勢＋顔距離(Z)</h1>
    <button id="startBtn">測定開始</button>
    <div class="video-area">
      <video id="video" autoplay muted playsinline></video>
      <canvas id="canvas"></canvas>
    </div>
    <div id="output">読み取り中...</div>
    <div id="warning">測定待機中</div>
  </div>

  <!-- MediaPipe -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const output = document.getElementById('output');
    const warning = document.getElementById('warning');
    const startBtn = document.getElementById('startBtn');

    let currentPitch = 0;
    let currentRoll = 0;

    function handleOrientation(event) {
      currentPitch = event.beta || 0;
      currentRoll = event.gamma || 0;
    }

    const faceMesh = new FaceMesh({
      locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
    });

    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: false,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    faceMesh.onResults(results => {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

      if (!results.multiFaceLandmarks || results.multiFaceLandmarks.length === 0) {
        output.textContent = "顔が見つかりません";
        warning.textContent = "顔が検出できません";
        warning.style.color = "red";
        return;
      }

      const lm = results.multiFaceLandmarks[0];
      const nose = lm[1];
      const chin = lm[152];

      const yDiff = chin.y - nose.y;
      let faceDirection = "";
      if (yDiff < 0.13) faceDirection = "down";
      else if (yDiff > 0.19) faceDirection = "up";
      else faceDirection = "straight";

      const noseZ = nose.z;
      let faceProximity = "";
      if (noseZ < -0.15) faceProximity = "顔が近い";
      else if (noseZ > -0.1) faceProximity = "顔が遠い";
      else faceProximity = "通常距離";

      output.textContent =
        `前後傾き（Pitch）: ${currentPitch.toFixed(2)}°\n` +
        `左右傾き（Roll）: ${currentRoll.toFixed(2)}°\n` +
        `顔向き: ${faceDirection}\n` +
        `顔距離: ${faceProximity}\n` +
        `鼻Z座標: ${noseZ.toFixed(4)}`;

      let isBent = false;
      if (faceProximity === "顔が近い" && currentPitch <= 30) {
        isBent = true;
      } else {
        if (currentPitch <= 40) {
          if (faceDirection === "down" || faceDirection === "straight") isBent = true;
        } else {
          if (faceDirection === "down") isBent = true;
        }
      }

      warning.textContent = isBent ? "首が曲がっています" : "首は曲がっていません";
      warning.style.color = isBent ? "red" : "green";
    });

    async function initCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "user" }, audio: false
      });
      video.srcObject = stream;
      video.addEventListener('loadedmetadata', () => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
      });
    }

    async function startAll() {
      if (
        typeof DeviceOrientationEvent !== 'undefined' &&
        typeof DeviceOrientationEvent.requestPermission === 'function'
      ) {
        try {
          const res = await DeviceOrientationEvent.requestPermission();
          if (res === 'granted') {
            window.addEventListener('deviceorientation', handleOrientation);
          } else {
            output.textContent = 'センサーの利用が許可されませんでした。';
            return;
          }
        } catch {
          output.textContent = 'センサー許可でエラーが発生しました。';
          return;
        }
      } else {
        window.addEventListener('deviceorientation', handleOrientation);
      }

      await initCamera();

      const camera = new Camera(video, {
        onFrame: async () => {
          await faceMesh.send({ image: video });
        },
        width: 640,
        height: 480
      });
      camera.start();

      startBtn.style.display = 'none';
      warning.textContent = '測定中...';
    }

    window.onload = () => {
      startBtn.onclick = startAll;
    };
  </script>
</body>
</html>
